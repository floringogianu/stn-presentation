section.left
  h2 Spatial Transformer Networks
  p Architecture

section.left(data-background="#FFF")
  h3 Spatial Transformer Module
  img(src="/img/spatial_transformer.png")

section.left.fragments
  h3 1. Localization Network
  ul
    li.fragment Takes a $\mathrm{U} \in \mathbb{R}^{H x W x C}$ tensor...
    li.fragment ...and learns $\theta$ parameters
    li.fragment Can be either a FCN or a CNN...
    li.fragment ...but it needs to include a final regression layer to produce the transformation parameters $\theta$


section.left.fragments
  h3 2. Parameterised Sampling Grid
  ul
    li.fragment Warps the input by applying to each pixel a sampling kernel centered at a particular location
    li.fragment Output pixels are defined to lie on a regular grid $G =\{G_i\}$ of pixels $G_i = (x_i^t,y_i^t)$
    li.fragment Both source and target coordinates are normalized

section(data-background="#FFF")
  h3.left 2. PSG - Affine Transformation
  img(src="/img/sampling_grid.png" style="max-width: 70%; margin: 0 auto")
  p(style="font-size: 70%;")
    | $$\begin{pmatrix} x_i^s \\ y_i^s \end{pmatrix}= \mathcal{T}(G_i) =
    | \mathrm{A}_{\theta}\begin{pmatrix} x_i^t \\ y_i^t \\ 1 \end{pmatrix} =
    | \begin{bmatrix} \theta_{11} & \theta_{12} & \theta_{13} \\ \theta_{21}
    | & \theta_{22} & \theta_{23} \end{bmatrix} \begin{pmatrix} x_i^t \\
    | y_i^t \\ 1 \end{pmatrix}$$ 

section.left.fragments
  h3 2. PSG - Beyond Affine
  ul
    li.fragment The class of transformations can be more constrained, as used for attention.
    li.fragment Or more general: Eg. eight parameters can encode plane projective transformations and thin plate spline transformations.
    li.fragment In fact it can have any parameterised form, provided that is differnetiable with respect to the parameters...
    li.fragment ...so that we can backpropagate the gradients.


section.left.fragments
  h3 3. Differentiable Image Sampling
  p.fragment(style="font-size: 60%;") Because we move pixels around during a transformation, we need to sample them.
  p.fragment(style="font-size: 60%;") A sampler must take the set of sampling points $\mathcal{T}_{\theta}(G)$, along with input U and produce the sampled output V.
  p.fragment(style="font-size: 60%;")    
    | $$V_i^c = \displaystyle\sum_{n}^{H} \displaystyle\sum_{m}^{W} 
    | U^{c}_{nm} k(x_i^s - m; \mathbf{\Phi}_x)k(y_i^s - n; \mathbf{\Phi}_y)
    | \quad \forall i \in [1 \ldots H'W'] \quad \forall c \in [1 \ldots C]$$ 
  p.fragment(style="font-size: 60%;") $\phi_x$ and $\phi_y$ are the parameters of a generic sample kernel $k()$ which defines the image interpolation

section.left
  h3 3. Example - Integer Sampling Kernel
  p(style="font-size: 60%;") Copy the value at the nearest pixel to $(x_i^s,y_i^s)$ to the output location $(x_i^s,y_i^s)$
  p(style="font-size: 70%;")
    | $$V_i^c = \displaystyle\sum_{n}^{H} \displaystyle\sum_{m}^{W}  
    | U^{c}_{nm} \delta(\lfloor x_i^s + 0.5 \rfloor -m)
    | \delta(\lfloor y_i^s + 0.5 \rfloor -n)$$
  ul.fragments
    li.fragment $\lfloor x + 0.5\rfloor$ rounds $x$ to the nearest integer.
    li.fragment $\delta()$ is the Kronecker delta function.

section.left
  h3 3. Real deal - Bilinear Sampling Kernel
  div
    img(src="/img/bilinear_interpolation.png" style="max-width: 30%; float: left; background-color: #FFF")
    div(style="float: right; max-width: 65%;")
      p(style="font-size: 60%;")
        | $$V_i^c = \displaystyle\sum_{n}^{H} \displaystyle\sum_{m}^{W} 
        | U^{c}_{nm} \max (0, 1 - \vert x_i^s - m \vert) \max (0, 1 - \vert y_i^s -n \vert)$$
      ul.fragments
        li.fragment $\max (0, 1 - \vert x_i^s - m \vert)$ makes sure we only look at the four adjacent pixels.

section.left
  h3 Differentiability with respect to $U$ 
  p(style="font-size: 80%;")
    | $$\frac{\partial V_i^c}{\partial U^c_{nm}} =
    | \displaystyle\sum_{n}^{H} \displaystyle\sum_{m}^{W}
    | \max (0, 1 - \vert x_i^s - m \vert) \max (0, 1 - \vert y_i^s -n \vert)$$

section.left
  h3 Differentiability with respect to $G$ 
  p(style="font-size: 70%;")
    | $$\frac{\partial V_i^c}{\partial x_i^s} =
    | \displaystyle\sum_{n}^{H} \displaystyle\sum_{m}^{W}
    | U^{c}_{nm}\max (0, 1 - \vert y_i^s -n \vert)
    | \begin{cases} 0 & \text{if} \; \vert m - x_i^s \vert \ge 1 \\
    | 1 & \text{if} \; m \ge x_i^s \\ -1 & \text{if} \; m < x_i^s \end{cases}$$
  ul
    li.fragment Any sampling kernel works as long as subgradients can be defined with respect to $G$
    li.fragment The affine transformation also needs to be differentiable so that we backpropagate the loss gradients back to the transformation parameters $\theta$

section.left(data-background="#FFF")
  p The combination of localisation network, grid generator, and sampler forms a spatial transformer.
  img(src="/img/spatial_transformer.png")

section.left.fragments
  h3 Spatial Transformer Networks (I)
  ul
    li.fragment Self-contained module that can be dropped into a CNN or FCN at any point...
    li.fragment ...and in any number
    li.fragment Computationally very cheap
    li.fragment Knoweledge of how to transform each training sample is cached in the weights of the localisation net...
    li.fragment ...and also in the weights of the layers previous to a ST

section.left.fragments
  h3 Spatial Tranformer Networks (II)
  ul
    li.fragment We can also feed the output of the localisation net, $\theta$ params, to the rest of the network, as it encodes transformation
    li.fragment Multiple STNs in parallel, if there are multiple objects or parts of interest in a feature map...
    li.fragment ...this is also a limitation
